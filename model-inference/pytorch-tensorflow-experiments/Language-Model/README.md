Run inference on question-answering model using huggingface with loaded data from postgres by using connectorX


Models:
- deepset/tinyroberta-squad2 (81.5M parameters, 326 MB)
- deepset/roberta-base-squad2 (124M parameters, 496 MB)
- deepset/bert-large-uncased-whole-word-masking-squad2 (335M parameters, 1372 MB)

Dataset:

Question Answering Dataset - SQuAD 2.0 [Link](https://rajpurkar.github.io/SQuAD-explorer/)

Run:

```bash
python huggingface_lm_connectorX.py
```
